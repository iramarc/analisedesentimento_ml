Projeto de Análise de Sentimentos
Introdução
Este projeto utiliza um modelo de análise de sentimentos para classificar textos em categorias de sentimentos (POSITIVO, NEUTRAL, NEGATIVO). A aplicação é construída usando Flask e a biblioteca transformers da Hugging Face.

Pré-requisitos
Certifique-se de ter os seguintes softwares instalados:

Visual Studio Code

Node.js(versão patch)

Python (versão patch)

Anaconda3

Cypress (instalado via PowerShell)

Microsoft Visual Studio Installer

Rust

Instalação
Siga os passos abaixo para configurar o ambiente:

Instale o Visual Studio Code, Node.js, Python e Anaconda3.

Instale o Cypress via PowerShell e libere a utilização de scripts:

sh
Get-ExecutionPolicy
Set-ExecutionPolicy RemoteSigned
Instale as ferramentas de build do Visual Studio para desenvolvimento em C++.

Instale o Rust:

sh
rustup-init.exe
Execute o Visual Studio Code e instale as extensões do Python e Live Server.

Instale as dependências do projeto:

sh
npm install cypress
python -m ensurepip --upgrade
pip install --upgrade setuptools
pip install -r requirements.txt
pip install torch
Uso
Para executar a aplicação, siga os passos abaixo:

Inicie o servidor Flask:

sh
python app.py
A aplicação estará disponível em http://0.0.0.0:5000.

Envie uma requisição POST para o endpoint /predict com um JSON contendo o texto a ser analisado:

json
{
    "text": "Seu texto aqui"
}
Arquivos Principais
app.py: Contém a lógica principal da aplicação Flask.

benchmark_quality.py: Similar ao app.py, utilizado para benchmarks de qualidade.

benchmark.py: Script para medir o tempo de resposta da API e verificar se está dentro do limite aceitável.

cypress.config.js: Configuração do Cypress para testes end-to-end.

index.html: Interface web para enviar textos e visualizar os resultados da análise de sentimentos.

package.json: Arquivo de configuração do Node.jscom as dependências de desenvolvimento.

requirements.txt: Lista de dependências Python necessárias para o projeto.

validation_data.json: Dados de validação para testar a precisão do modelo de análise de sentimentos.

sentiment_analysis.cy.js: Testes end-to-end para verificar a funcionalidade e desempenho da API de análise de sentimentos.

CI/CD com GitHub Actions
Este projeto utiliza GitHub Actions para automação de CI/CD. O pipeline é configurado para executar testes automatizados e deploy contínuo.

Configuração do Pipeline
Crie um arquivo .github/workflows/ci.yml no repositório.

Adicione a configuração do pipeline:

yaml
name: CI/CD Pipeline

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      # Passo 1: Faz o checkout do código
      - name: Checkout code
        uses: actions/checkout@v2

      # Passo 2: Configura o Python
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.x'

      # Passo 3: Instala as dependências do Python
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install torch  # Instala PyTorch
          pip install pytest  # Instala pytest

      # Passo 4: Configura o Node.js
      - name: Set up Node.js
        uses: actions/setup-node@v2
        with:
          node-version: '14'

      # Passo 5: Instala as dependências do Node.js
      - name: Install Node.js dependencies
        run: npm install

      # Passo 6: Inicia o servidor Flask em segundo plano
      - name: Start Flask server
        run: |
          nohup python app.py &  # Inicia o servidor Flask em segundo plano
        env:
          FLASK_ENV: development

      # Passo 7: Aguarda o Flask ficar pronto
      - name: Wait for Flask server to be ready
        run: sleep 20  # Aumenta o tempo de espera para garantir que o servidor Flask esteja pronto

      # Passo 8: Executa os testes do Cypress
      - name: Run Cypress tests
        run: npx cypress run

      # Passo 9: Executa os testes do Python (com `pytest`)
      - name: Run Python tests
        run: |
          export PYTHONPATH=$PYTHONPATH:$(pwd)  # Define a variável de ambiente PYTHONPATH
          pytest tests/test_benchmark.py  # Executa o teste benchmark
          pytest tests/test_benchmark_quality.py  # Executa o teste benchmark_quality
Resultados de Benchmarking
Os testes de benchmarking foram realizados para medir o desempenho da API e a qualidade das inferências.

Métricas de Desempenho
Tempo de resposta médio: 150ms

Taxa de sucesso: 98%

Avaliações de Qualidade de Inferência
Precisão: 88.57%

Recall (Positivo): 95.00%

F1 Score (Positivo): 97.44%

Recall (Negativo): 84.62%

F1 Score (Negativo): 91.67%

Garantia de Qualidade das Inferências
Para garantir que as inferências do modelo sejam precisas, implementamos as seguintes estratégias:

Validação cruzada: Utilizamos validação cruzada para avaliar a performance do modelo.

Ajuste de hiperparâmetros: Realizamos ajustes nos hiperparâmetros para otimizar o desempenho.

Testes de validação: Utilizamos um conjunto de dados de validação para testar a precisão do modelo.

Desafios Enfrentados
Tempo de inferência: Otimizamos o código para reduzir o tempo de inferência sem comprometer a precisão.

Possíveis Aplicações do Projeto
Monitoramento de Redes Sociais: Analisar sentimentos em postagens e comentários para entender a percepção do público sobre uma marca ou produto.

Atendimento ao Cliente: Avaliar o sentimento em interações de atendimento ao cliente para identificar problemas e melhorar a satisfação do cliente.

Análise de Feedback: Processar feedback de clientes e funcionários para identificar áreas de melhoria e tomar decisões informadas.

Pesquisa de Mercado: Analisar opiniões e sentimentos em pesquisas de mercado para entender as preferências e necessidades dos consumidores.

Futura Atualização: Criação de um Banco de Dados Personalizado
Descrição
Criar um banco de dados personalizado para melhorar a precisão do modelo, especialmente para a categoria neutra.

Passos
Coleta de Dados: Coletar um conjunto de dados diversificado contendo textos classificados como positivos, negativos e neutros.

Criação do Banco de Dados: Armazenar os dados coletados em um banco de dados estruturado.

Treinamento do Modelo: Treinar o modelo de machine learning utilizando o banco de dados personalizado.

Integração com a API: Integrar o modelo treinado com a API de análise de sentimentos.

Monitoramento e Avaliação: Monitorar a performance do modelo em produção e avaliar continuamente sua precisão.

Tecnologias Utilizadas
MySQL, PostgreSQL, MongoDB

scikit-learn, TensorFlow, PyTorch

Flask, FastAPI

Prometheus, Grafana, ELK Stack